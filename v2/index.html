<!DOCTYPE html>
<html lang="en">
<head>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="shortcut icon" type="image/png" href="https://www.nvidia.com/favicon.ico">
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fast-dLLM</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.5; /* Adjust this value to make the spacing larger */
            margin: 0;
            padding: 0;
            color: black;
             /* background-image: url('asset/samples/pexels-photo-28821825.jpeg'); Background image */
            background-size: contain; /* Cover the entire viewport */
            background-attachment: fixed; /* Fixed background */
            background-position: center;
            direction: ltr;
        }
        .hero {
            text-align: center;
            padding: 50px 0;
            background-color: #fff;
            border-bottom-left-radius: 20px;
            border-bottom-right-radius: 20px;
        }
        .hero h1 {
            font-size: 5em;
            margin: 0.2em 0;
        }
        .hero h2 {
            font-size: 2.8em;
            margin: 0.2em 0;
            font-weight: normal;
            line-height: 1.4; /* Adjust this value to make the spacing larger */
        }
        .hero p {
            font-size: 1.4em;
            margin-bottom: 1em;
        }
        .button {
            display: inline-block;
            padding: 10px 20px;
            margin: 5px;
            font-size: 0.9em;
            color: white;
            background-color: black;
            border-radius: 30px;
            text-decoration: none;
        }
        .button_green {
            display: inline-block;
            padding: 10px 20px;
            margin: 5px;
            font-size: 0.9em;
            color: black;
            background-color: #76b900;
            border-radius: 30px;
            text-decoration: none;
        }
        .gallery-container {
            max-width: 77%; /* Limit the width of the gallery */
            margin: 0 auto; /* Center the gallery */
            padding: 20px 0; /* Add some padding on top and bottom */
        }
        .gallery {
            display: grid;
            grid-template-columns: repeat(12, 1fr); /* 12 columns grid */
            grid-auto-rows: 150px; /* Adjust row height */
            gap: 10px;
        }
        .gallery-item {
            overflow: hidden;
            /*aspect-ratio: 1/1; !* Keep the aspect ratio of the images *!*/
        }
        .gallery-item img {
            width: 100%;
            height: 100%;
            object-fit: cover;
            cursor: pointer; /* Cursor change on hover */
            border-radius: 10px; /* Rounded corners */
            transition: transform 0.3s ease; /* Add smooth transition */
        }
        /* Image scaling on hover */
        .gallery-item img:hover {
            transform: scale(1.2); /* Scale the image to 1.2 times its original size */
        }
        /* Define specific grid item placements */
        .item1 { grid-column: span 3; grid-row: span 3; } /* Large image */
        .item2 { grid-column: span 7; grid-row: span 3; } /* Smaller image */
        .item3 { grid-column: span 2; grid-row: span 3; } /* Horizontal image */

        .item4 { grid-column: span 6; grid-row: span 3; } /* Wide image */
        .item5 { grid-column: span 4; grid-row: span 3; } /* Wide image */
        .item6 { grid-column: span 2; grid-row: span 3; } /* Wide image */

        .item7 { grid-column: span 4; grid-row: span 4; } /* Square image */
        .item8 { grid-column: span 3; grid-row: span 4; } /* Vertical image */
        .item9 { grid-column: span 2; grid-row: span 4; } /* Vertical image */
        .item10 { grid-column: span 3; grid-row: span 4; } /* Another larger image */

        .item11 { grid-column: span 2; grid-row: span 3; } /* Another larger image */
        .item12 { grid-column: span 4; grid-row: span 3; } /* Another larger image */
        .item13 { grid-column: span 2; grid-row: span 3; } /* Another larger image */
        .item14 { grid-column: span 4; grid-row: span 3; } /* Another larger image */

        .item15 { grid-column: span 4; grid-row: span 4; } /* Another larger image */
        .item16 { grid-column: span 4; grid-row: span 4; } /* Another larger image */
        .item17 { grid-column: span 2; grid-row: span 4; } /* Another larger image */
        .item18 { grid-column: span 2; grid-row: span 4; } /* Another larger image */

        .item19 { grid-column: span 3; grid-row: span 5; } /* Another larger image */
        .item20 { grid-column: span 3; grid-row: span 5; } /* Another larger image */
        .item21 { grid-column: span 3; grid-row: span 5; } /* Another larger image */
        .item22 { grid-column: span 3; grid-row: span 5; } /* Another larger image */

        .item23 { grid-column: span 6; grid-row: span 4; } /* Another larger image */
        .item24 { grid-column: span 3; grid-row: span 4; } /* Another larger image */
        .item25 { grid-column: span 3; grid-row: span 4; } /* Another larger image */

        .item26 { grid-column: span 3; grid-row: span 5; } /* Another larger image */
        .item27 { grid-column: span 3; grid-row: span 5; } /* Another larger image */
        .item28 { grid-column: span 6; grid-row: span 5; } /* Another larger image */

        .item29 { grid-column: span 3; grid-row: span 3; } /* Another larger image */
        .item30 { grid-column: span 3; grid-row: span 3; } /* Another larger image */
        .item31 { grid-column: span 3; grid-row: span 3; } /* Another larger image */
        .item32 { grid-column: span 3; grid-row: span 3; } /* Another larger image */


        /* Modal styling */
        #modal {
            display: none; /* Hidden by default */
            position: fixed; /* Stay in place */
            z-index: 1; /* Sit on top */
            left: 0;
            top: 0;
            width: 100%; /* Full width */
            height: 100%; /* Full height */
            overflow: auto; /* Enable scroll if needed */
            background-color: rgba(0, 0, 0, 0.9); /* Black w/ opacity */
            justify-content: center; /* Horizontally center the image */
            flex-direction: column;
            align-items: center; /* Center align items vertically */
        }
        #modal img {
            margin: auto;
            display: block;
            max-width: 77%;
            max-height: 77%; /* Ensure the image doesn't overflow vertically */
            object-fit: contain; /* Make sure the aspect ratio is preserved */
        }
        #modal-description {
            color: white;
            text-align: center;
            margin-top: 10px; /* Adjust this value to move text closer to the image */
            font-size: 1.2em;
        }
        .description {
            font-family: Arial, sans-serif;
            font-style: normal;
            font-size: 17px;
            line-height: 1.47;
            color: #333;
            /*color: black; !* Text color *!*/
            letter-spacing: -0.022em;
            font-weight: 400;
            background-color: #fff; /* Solid background color that spans the entire width */
            padding: 20px 0; /* Add vertical padding */
            text-align: center; /* Center align text */
            border-top-left-radius: 20px;
            border-top-right-radius: 20px;
            box-shadow: 2px 4px 12px #00000054;
        }
        .description_noborder {
            font-family: Arial, sans-serif;
            font-style: normal;
            font-size: 17px;
            line-height: 1.47;
            color: #333;
            /*color: black; !* Text color *!*/
            letter-spacing: -0.022em;
            font-weight: 400;
            background-color: #fff; /* Solid background color that spans the entire width */
            padding: 20px 0; /* Add vertical padding */
            text-align: center; /* Center align text */
        }
        .description-content {
            /*background-color: rgba(255, 255, 255, 0.1); !* Semi-transparent background inside the section *!*/
            /*border: 2px solid #555; !* Adding a lighter border *!*/
            max-width: 65%; /* Limit the width to 80% of the screen */
            margin: 0 auto; /* Center the content horizontally */
            padding: 20px; /* Padding inside the border */
            font-style: normal;
            border-radius: 18px;
            /*box-shadow: 2px 4px 12px #00000014;*/
        }
        .description-content h2 {
            display: block;
            color: black;
            font-size: 1.5em;
            line-height: 1.125;
            letter-spacing: .004em;
            font-weight: 600;
            text-align: left; /* Center-align the h2 */
            margin-block-start: 0.83em;
            margin-block-end: 0.83em;
            margin-inline-start: 0px;
            margin-inline-end: 0px;
            font-style: normal;
        }
        .description-content p {
            font-size: 1.1em;
            text-align: left; /* Left-align the p */
            font-weight: normal;
        }
        .citation {
            /*background-color: #333; !* Solid background color that spans the entire width *!*/
            font-family: Arial, sans-serif;
            background-color: #fff; /* Solid background color that spans the entire width */
            color: black;
            padding: 10px;
            text-align: center;
            margin-top: 10px;
        }
        .citation-content {
            text-align: left;
            border-radius: 15px; /* Rounded corners */
            font-size: 0.8em;
            max-width: 80%; /* Limit the width to 80% of the screen */
            margin: 0 auto; /* Center the content horizontally */
            margin-top: -30px;
            padding: 0; /* Padding inside the border */
            background-color: #f5f5f5; /* Semi-transparent background inside the section */
            overflow-x: auto; /* Horizontal scrolling */
            overflow-y: hidden; /* Prevent vertical scrolling */
            white-space: nowrap; /* Prevent line breaks */
        }
        .citation-content h2 {
            font-size: 2em;
            text-align: left;
            font-weight: normal;
        }
        .citation pre {
            border-radius: 15px; /* Rounded corners */
            max-width: 90%; /* Limit the width to 80% of the screen */
            text-align: left;
        }
        .footer {
            background-color: #f5f5f5;
            box-shadow: 2px 4px 12px #00000054;
            color: #333;
            padding: 20px;
            text-align: center;
            margin-top: -20px;
            border-top-left-radius: 20px;
            border-top-right-radius: 20px;
        }
        .footer a {
            color: dodgerblue;
            text-decoration: none;
        }
        .inserted-image {
            max-width: 80%;  /* Set the maximum width for the image */
            height: auto;    /* Ensure the height adjusts automatically to maintain aspect ratio */
            margin: 30px;  /* Add space above and below the image */
            margin-top: 10px;
            display: block;  /* Make sure the image is treated as a block-level element */
            margin-left: auto; /* Center the image horizontally */
            margin-right: auto;
            border-radius: 10px;
            box-shadow: 2px 2px 10px 3px #00000030;
        }
        .inserted-image-noshadow {
            max-width: 30%;  /* Set the maximum width for the image */
            margin-left: auto; /* Center the image horizontally */
            margin-right: auto;
            border-radius: 10px;
        }
        .video-container {
            text-align: center;  /* Center the video horizontally */
            margin: 20px 0;  /* Add some vertical margin around the video */
        }
        video {
            max-width: 80%;  /* The video will scale to fit the container */
            height: auto;  /* Maintain the video's aspect ratio */
            border-radius: 10px;  /* Rounded corners for the video */
            box-shadow: 2px 2px 10px 3px #00000054;
        }
        .logo {
            color: black;
            display: flex;
            justify-content: center;
            /*justify-content: left;*/
            align-items: center;
            text-align: center;
            gap: 60px;
        }
        .logo-sup {
            position: absolute;
            top: -5px; /* Adjust this value to position it closer to the top */
            right: -10px; /* Adjust this value to move it horizontally */
            font-size: 14px; /* Increase the size of the superscript */
            color: black; /* Change the color if needed */
          }
        /* Image comparison container */
        .image-comparison-container {
            background-color: #fff; /* Solid background color that spans the entire width */
        }
        .image-comparison-content {
            position: relative;
            width: 580px;  /* Adjust the width as needed */
            height: 402px; /* Adjust the height as needed */
            overflow: hidden; /* Make sure overflow isn't hiding any part of the images */
            margin: 0 auto;
            margin-top: -20px;
            cursor: ew-resize;
            border-radius: 10px;
        }
        .image-comparison-content img {
            position: absolute;
            width: 100%;
            height: 99%;
            background-color: #fff;
            object-fit: contain; /* Use contain to ensure the whole image is visible */
        }
        .image-comparison-content .slider {
            position: absolute;
            top: 0;
            bottom: 0;
            left: 50%;
            width: 2px;
            background-color: #fff;
            z-index: 10;
        }
        .image-comparison-content .slider-black {
            position: absolute;
            top: 0;
            bottom: 0;
            left: 50%;
            width: 2px;
            background-color: black;
            z-index: 10;
        }
        .demo {
            margin-top: -20px;
            background-color: #fff;
            text-align: center;
        }
        .demo iframe {
            width: 50%;
        }
        .image-comparison-content .image-2 {
            clip-path: inset(0 0 0 50%);
        }
        .image-comparison-content .image-4 {
            clip-path: inset(0 0 0 50%);
        }
        @media (max-width: 4096px) {
            .gallery {
                /*grid-template-columns: repeat(auto-fit, minmax(40px, 1fr)); !* Adjust columns for smaller screens *!*/
                grid-auto-columns: 100px; /* Adjust columns for smaller screens */
                grid-auto-rows: 200px; /* Set a fixed height for the grid items */
            }
            .demo iframe {
                width: 800px;
            }
        }
        @media (max-width: 2048px) {
            .gallery {
                /*grid-template-columns: repeat(auto-fit, minmax(40px, 1fr)); !* Adjust columns for smaller screens *!*/
                grid-auto-columns: 60px; /* Adjust columns for smaller screens */
                grid-auto-rows: 90px; /* Set a fixed height for the grid items */
            }
            .demo iframe {
                width: 800px;
            }
        }
        @media (min-width: 2048px) {
            .description-content {
                max-width: 728px; /* Limit the width to 80% of the screen */
                padding: 10px; /* Padding inside the border */
            }
            .citation-content {
                max-width: 728px; /* Limit the width to 80% of the screen */
                padding: 10px; /* Padding inside the border */
            }
            .inserted-image {
                max-width: 1024px; /* Limit the width to 80% of the screen */
                padding: 10px; /* Padding inside the border */
            }
            .inserted-image-noshadow {
                max-width: 384px; /* Limit the width to 80% of the screen */
            }
            video {
                max-width: 1024px;  /* The video will scale to fit the container */
            }
        }
        @media (max-width: 1024px) {
            .gallery {
                /*grid-template-columns: repeat(auto-fit, minmax(40px, 1fr)); !* Adjust columns for smaller screens *!*/
                grid-auto-columns: 40px; /* Adjust columns for smaller screens */
                grid-auto-rows: 70px; /* Set a fixed height for the grid items */
            }
            .demo iframe {
                width: 80%;
            }
        }
        @media (min-width: 1024px) {
            .description-content {
                max-width: 728px; /* Limit the width to 80% of the screen */
                padding: 10px; /* Padding inside the border */
            }
            .citation-content {
                max-width: 728px; /* Limit the width to 80% of the screen */
                padding: 10px; /* Padding inside the border */
            }
            .inserted-image {
                max-width: 826px; /* Limit the width to 80% of the screen */
                padding: 5px; /* Padding inside the border */
            }
            .inserted-image-noshadow {
                max-width: 384px; /* Limit the width to 80% of the screen */
            }
            video {
                max-width: 728px;  /* The video will scale to fit the container */
            }
        }
        @media (max-width: 768px) {
            .gallery {
                /*grid-template-columns: repeat(auto-fit, minmax(40px, 1fr)); !* Adjust columns for smaller screens *!*/
                grid-auto-columns: 20px; /* Adjust columns for smaller screens */
                grid-auto-rows: 30px; /* Set a fixed height for the grid items */
                gap: 5px;
            }
            .gallery-container {
                max-width: 85%; /* Limit the width of the gallery */
                padding: 10px 0; /* Add some padding on top and bottom */
            }
            .hero h1 {
                font-size: 3em;
            }
            .hero h2 {
                font-size: 2em;
            }
            .hero p {
                font-size: 1em;
            }
            .description-content {
                max-width: 92%; /* Limit the width to 80% of the screen */
                padding: 10px; /* Padding inside the border */
            }
            .citation-content {
                max-width: 92%; /* Limit the width to 80% of the screen */
                padding: 10px; /* Padding inside the border */
            }
            .inserted-image {
                max-width: 95%; /* Limit the width to 80% of the screen */
                padding: 5px; /* Padding inside the border */
            }
            .inserted-image-noshadow {
                max-width: 50%; /* Limit the width to 80% of the screen */
                margin-left: auto; /* Center the image horizontally */
                margin-right: auto;
            }
            .image-comparison-content {
                max-height: 300px; /* Limit the width to 80% of the screen */
                max-width: 92%;
            }
            video {
                max-width: 92%;  /* The video will scale to fit the container */
            }
            .logo {
                gap: 10px;
            }
            .demo iframe {
                width: 95%;
            }
        }
        /* Dark mode */
        @media (prefers-color-scheme: dark) {
            .description {
                background-color: #333; /* Dark color for dark mode */
                color: white; /* Light text color for dark mode */
            }
            .description_noborder {
                background-color: #333; /* Dark color for dark mode */
                color: white; /* Light text color for dark mode */
            }
            .description_noborder h2{
                background-color: #333; /* Dark color for dark mode */
                color: white; /* Light text color for dark mode */
            }
            .description-content h2 {
                background-color: #333; /* Dark color for dark mode */
                color: white; /* Light text color for dark mode */
            }
            .citation {
                background-color: #333; /* Dark color for dark mode */
                color: white; /* Light text color for dark mode */
            }
            .citation-content {
                background-color: #555; /* Dark color for dark mode */
            }
            .citation-content h2 {
                background-color: #555; /* Dark color for dark mode */
            }
            .footer {
                background-color: #222; /* Dark color for dark mode */
                color: white;
            }
            .image-comparison-container {
                background-color: #333; /* Dark color for dark mode */
            }
            .demo {
                background-color: #333;
            }
        }
    </style>
</head>
<body>

    <div class="hero">

        <h2>Fast-dLLM v2: Efficient Block-Diffusion Large Language Model</h2>

        <!-- Add author and institution information -->
        <div style="margin-top: 20px; text-align: center;">
            <p style="font-size: 1.3em; margin-bottom: 5px;">
                <a href="https://hills-code.github.io/" target="_blank" style="color: #76b900;">Chengyue Wu</a><sup>1,2</sup>,
                <a href="https://haozhang534.github.io/" target="_blank" style="color: #76b900;">Hao Zhang</a><sup>2</sup>,
                <a href="https://scholar.google.com/citations?user=aA70TOwAAAAJ&hl=en" target="_blank" style="color: #76b900;">Shuchen Xue</a><sup>2</sup>,
                <a href="https://scholar.google.com/citations?user=NDFQrLQAAAAJ&hl=en" target="_blank" style="color: #76b900;">Shizhe Diao</a><sup>2</sup>,
                <a href="https://www.yongganfu.com/" target="_blank" style="color: #76b900;">Yonggan Fu</a><sup>2</sup>,
                <a href="https://zhijianliu.com/" target="_blank" style="color: #76b900;">Zhijian Liu</a><sup>2</sup>,
                <a href="https://www.pmolchanov.com/" target="_blank" style="color: #76b900;">Pavlo Molchanov</a><sup>2</sup>,
                <a href="http://luoping.me/" target="_blank" style="color: #76b900;">Ping Luo</a><sup>1</sup>,
                <a href="https://hanlab.mit.edu/songhan/" target="_blank" style="color: #76b900;">Song Han</a><sup>2,3</sup>,
                <a href="https://xieenze.github.io/" target="_blank" style="color: #76b900;">Enze Xie</a><sup>2</sup>
            </p>
            <p style="font-size: 1.2em; color: #888;">
                <sup>1</sup>HKU, <sup>2</sup>NVIDIA, <sup>3</sup>MIT
                <!-- <br> -->
                <!-- *Equal contribution -->
            </p>
        </div>
<!--        <div style="overflow: hidden; background-color: #6699cc;">-->
        <div style="overflow: hidden; background-color: #fff;">
          <div class="logo" style="padding: 12px;">
            <a href="" style="text-decoration: none; font-size: 16px;">
                <img src="../asset/hku.png" alt="HKU Logo" style="width: auto; height: 40px;">
            </a>
            <a href="https://www.nvidia.com/" style="text-decoration: none; font-size: 16px;">
              <img src="https://nv-tlabs.github.io/3DStyleNet/assets/nvidia.svg" alt="NVIDIA Logo" style="width: auto; height: 30px;">
            </a>
            <a href="https://hanlab.mit.edu/" style="text-decoration: none; font-size: 16px;">
              <img src="../asset/mit_han.png" alt="MIT Logo" style="width: auto; height: 30px;">
            </a>
          </div>
        </div>

        <a href="paper/fast_dllm_v2.pdf" class="button">Paper</a>
        <a href="https://github.com/NVlabs/Fast-dLLM" class="button">Code</a>
        <a href="https://huggingface.co/Efficient-Large-Model/Fast_dLLM_7B" class="button">Model</a>
    </div>

        <!-- Video demonstration -->
        <div class="video-container">
            <video src="asset/demo.mp4"
                    autoplay
                    muted
                    loop
                    playsinline
                    controls>
                Your browser does not support the video tag.
            </video>
            <figcaption>
                Realtime throughput comparison between Fast-dLLM v2 and Qwen2.5-7B-Instruct.
            </figcaption>
            </div>
        
        <div class="description-content">
          <h2>About Fast-dLLM v2</h2>
          <p> Autoregressive (AR) large language models (LLMs) have achieved remarkable performance across a wide range of natural language tasks, 
            yet their inherent sequential decoding limits inference efficiency. In this work, we propose Fast-dLLM v2, a carefully designed block diffusion language model (dLLM) 
            that efficiently adapts pretrained AR models into dLLMs for parallel text generation, requiring only approximately 1B tokens of fine-tuning. 
            This represents a 500x reduction in training data compared to full-attention diffusion LLMs such as Dream (580B tokens), 
            while preserving the original model's performance. 
            Our approach introduces a novel training recipe that combines a block diffusion mechanism with a complementary attention mask, 
            enabling blockwise bidirectional context modeling without sacrificing AR training objectives. 
            To further accelerate decoding, we design a hierarchical caching mechanism: a block-level cache that stores historical context representations across blocks, 
            and a sub-block cache that enables efficient parallel generation within partially decoded blocks. Coupled with our parallel decoding pipeline, 
            Fast-dLLM v2 achieves up to 2.5x speedup over standard AR decoding without compromising generation quality. 
            Extensive experiments across diverse benchmarks demonstrate that Fast-dLLM v2 matches or surpasses AR baselines in accuracy, 
            while delivering state-of-the-art efficiency among dLLMs - marking a significant step toward the practical deployment of fast and accurate LLMs.
            </p>
        </div>

        <!-- Insert your image here -->
        <div class="description-content">
            <h2>Generation Process</h2>
              <p> The model generates text in an autoregressive manner at the block level. Each block is further divided into sub-blocks, which are decoded in parallel to enhance efficiency. Leveraging the block diffusion mechanism, the model naturally supports block-level caching. In addition, we incorporate a sub-block cache using the dual-cache strategy introduced in Fast-dLLM v1, enabling fast and efficient parallel decoding within blocks.
              </p>
          </div>
        <div style="width: 100%; display: flex; justify-content: center;">
            <figure style="display: flex; flex-direction: column; align-items: center; max-width: 900px; width: 100%;">
            <div style="display: flex; justify-content: center; width: 100%;">
                <img src="asset/visualization_animation.gif" alt="Overview" class="inserted-image" style="max-width: 80%; min-width: 120px;">
            </div>
        </div>

        <div class="description-content">
            <h2>Training Recipe</h2>
              <p> To better utilize the autoregressive representations, we adopt a <strong>token shift mechanism</strong>: each masked token is predicted using the logit of its preceding token, enabling the model to retain autoregressive characteristics. Meanwhile, our <strong>block-wise causal attention mask</strong> allows the model to access all clean tokens from previous blocks as well as the noisy tokens within the current block during training. Additionally, we introduce <strong>complementary masks</strong> that let the model learn to predict from alternate masking patterns, ensuring that every token position is eventually learned. This design allows for bidirectional context modeling within blocks while maintaining compatibility with original AR objectives, facilitating efficient and parallelizable text generation.
              </p>
          </div>
          <div style="width: 100%; display: flex; justify-content: center;">
            <figure style="display: flex; flex-direction: column; align-items: center; max-width: 900px; width: 100%;">
              <div style="display: flex; justify-content: center; width: 100%;">
                  <img src="asset/training_recipe.png" alt="Training recipe" class="inserted-image" style="max-width: 80%; min-width: 120px;">
              </div>
            </figure>
          </div>

        <div class="description-content">
            <h2>Throughput Comparison</h2>
              <p> We compare the inference throughput (tokens per second) and GSM8K accuracy of various language model variants on a single A100 GPU. <strong>Fast-dLLM v2 (7B, green)</strong> 
                significantly outperforms all baselines in both efficiency and accuracy. In panel (a), Fast-dLLM v2 achieves <strong>2.54× higher throughput</strong> than Qwen2.5-7B-Instruct 
                while improving accuracy by <strong>5.2%</strong> over Fast-dLLM-LLaDA. In panel (b), Fast-dLLM v2 demonstrates strong scalability, with throughput increasing from 102.5 tokens/sec at batch size 1 to 217.5 tokens/sec at batch size 4—substantially higher than Qwen2.5 and earlier Fast-dLLM variants (Dream and LLaDA). These results highlight the effectiveness of Fast-dLLM v2’s parallel decoding optimizations.
              </p>
          </div>
          <div style="width: 100%; display: flex; justify-content: center;">
            <figure style="display: flex; flex-direction: column; align-items: center; max-width: 900px; width: 100%;">
              <div style="display: flex; justify-content: center; width: 100%;">
                  <img src="asset/throughput.png" alt="Throughput comparison" class="inserted-image" style="max-width: 80%; min-width: 120px;">
              </div>
            </figure>
          </div>


        <div class="description-content">
            <h2>Benchmark Results</h2>
            We present a comprehensive benchmark comparison of Fast-dLLM v2 against several baseline models across a diverse set of tasks, including code generation (HumanEval, MBPP), mathematical reasoning (GSM8K, Math), instruction following (IFEval), and knowledge-intensive QA (MMLU, GPQA).

In the 1B-scale group, Fast-dLLM v2 (1.5B) achieves the highest average score of 45.0, outperforming all other models.
In the 7B+ group, Fast-dLLM v2 (7B) also attains the highest overall average score of 60.3, surpassing larger models such as LLaDA-MoE, Dream, and Qwen2.5-7B variants.

Notably, Qwen2.5-Nemo-FT models refer to autoregressive (AR) baselines fine-tuned on the same training data as Fast-dLLM v2, providing a fair comparison under equivalent data conditions.
These results demonstrate that Fast-dLLM v2 not only <strong>scales effectively but also delivers state-of-the-art performance and efficiency</strong>, validating the strength of its block diffusion-based decoding approach across model sizes and tasks.
        </div>
          <div>
            <img src="asset/benchmark_results.png" alt="Benchmark results." class="inserted-image">
          </div>
          


        <!--BibTex citation -->
        <!-- <div class="description-content">
            <h2 class="title">BibTeX</h2>
        </div>
        <section class="citation" id="BibTeX">
            <div class="citation-content">
                <pre><code></code></pre>
            </div>
        </section> -->

    </section>
    <!--End BibTex citation -->

    <!-- Footer Section -->
    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a
                                rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <!-- End Footer -->

    <script>
      // Function to open the modal and display the clicked image and description
      function openModal(img) {
          var modal = document.getElementById("modal");
          var modalImg = document.getElementById("modal-img");
          var modalDescription = document.getElementById("modal-description");

          modal.style.display = "flex";
          modalImg.src = img.src;
          modalDescription.textContent = img.getAttribute('data-description'); // Get description from data-description attribute
      }

      // Add click event listeners to all images in the gallery with their descriptions
      const images = document.querySelectorAll('.gallery-item img');
      images.forEach((img) => {
        img.addEventListener('click', () => openModal(img));
      });
    </script>

    <script>
        const container = document.querySelector('.image-comparison-content');
        const slider = document.querySelector('.slider');
        // const slider_black = document.querySelector('.slider-black');
        const image2 = document.querySelector('.image-2');
        // const image4 = document.querySelector('.image-4');

        container.addEventListener('mousemove', (e) => {
            const rect = container.getBoundingClientRect();
            let xPos = e.clientX - rect.left;

            if (xPos < 0) xPos = 0;
            if (xPos > rect.width) xPos = rect.width;

            const percentage = (xPos / rect.width) * 100;

            slider.style.left = `${percentage}%`;
            // slider_black.style.left = `${percentage}%`;
            image2.style.clipPath = `inset(0 0 0 ${percentage}%)`;
            // image4.style.clipPath = `inset(0 0 0 ${percentage}%)`;
        });
    </script>
</body>
</html>
